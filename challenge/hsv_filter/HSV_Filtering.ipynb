{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Filtering using HSV\n",
    "In the make_blue challenge, we were operating in the BGR \"colorspace\" (Blue, Green, Red), but there are other colorspaces -- including HSV (hue, saturation, value).  HSV is also three values, but they operate differently.\n",
    "\n",
    "You can get an idea by looking at this diagram:\n",
    "\n",
    "![HSV Color wheel](https://upload.wikimedia.org/wikipedia/commons/0/0d/HSV_color_solid_cylinder_alpha_lowgamma.png)\n",
    "\n",
    "The first step in leveraging HSV is to convert the image into the HSV colorspace...  Let's use our favorite image and convert to to HSV and see what it looks like.  We'll load up the image and display it standard first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_image_file(image_file):        # I used a function here to combine the test with the load\n",
    "    if(os.path.isfile(image_file)):     # os.path.isfile returns true if the file exists, why is this needed?\n",
    "\t    img = cv2.imread(image_file)\n",
    "    else:\n",
    "\t    print(\"Invalid file, exiting....\")\n",
    "\t    exit(1)\n",
    "    return(img)\n",
    "\n",
    "team_image_file = \"..\\..\\images\\Jagbots2017.jpg\"\n",
    "\n",
    "team_image_BGR = load_image_file(team_image_file)\n",
    "\n",
    "cv2.imshow(\"Image\", team_image_BGR)                          # this function will open a window with the image\n",
    "cv2.waitKey(0)                                    # this function will wait until a key is pressed\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've loaded it up, now let's convert it to the HSV colorspace.  This next snippet requires that the above code has been run, so be sure you ran it!\n",
    "\n",
    "We're going to create a new image in the HSV colorspace.  This conversion is similar to converting to Grayscale, but it produces an image that is color, but not the same colors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert from BGR to HSV\n",
    "#\n",
    "team_image_HSV = cv2.cvtColor(team_image_BGR, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"HSV Image\", team_image_HSV)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it all worked correctly, you're seeing a pretty different image -- like one that was taken using a nuclear camera flash.\n",
    "\n",
    "Obviously we are not doing this to make it prettier to human eyes -- so why bother?  We convert to HSV for the same reason we will often convert to Grayscale, it makes it easier to perform other operations -- like color filtering.\n",
    "\n",
    "Since we are going to be chasing the reflective tape used by FIRST, let's switch to a sample image from last season..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_image_file(image_file):        # I used a function here to combine the test with the load\n",
    "    if(os.path.isfile(image_file)):     # os.path.isfile returns true if the file exists, why is this needed?\n",
    "\t    img = cv2.imread(image_file)\n",
    "    else:\n",
    "\t    print(\"Invalid file, exiting....\")\n",
    "\t    exit(1)\n",
    "    return(img)\n",
    "\n",
    "image_file = \"../../images/tape_sample_images/sample7.png\"\n",
    "\n",
    "image_BGR = load_image_file(image_file)\n",
    "\n",
    "cv2.imshow(\"Image\", image_BGR)                  # this function will open a window with the image\n",
    "cv2.waitKey(0)                                  # this function will wait until a key is pressed\n",
    "    \n",
    "\n",
    "# convert from BGR to HSV\n",
    "#\n",
    "image_HSV = cv2.cvtColor(image_BGR, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"HSV Image\", image_HSV)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these images, you get an idea of why that tape is so special -- it really stands out.  Now let's try to filter for that color..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define range of green color in HSV\n",
    "lower_tape = np.array([50,90,110])\n",
    "upper_tape = np.array([100,255,255])\n",
    "\n",
    "# Threshold the HSV image to get only blue colors\n",
    "mask = cv2.inRange(image_HSV, lower_tape, upper_tape)\n",
    "\n",
    "# Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(image_BGR,image_BGR, mask= mask)\n",
    "\n",
    "cv2.imshow('image',image_BGR)\n",
    "cv2.imshow('mask',mask)\n",
    "cv2.imshow('res',res)\n",
    "\n",
    "# Let's define our kernel size\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "# Now we erode\n",
    "erosion = cv2.erode(res, kernel, iterations = 1)\n",
    "cv2.imshow('Erosion', erosion)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 2\n"
     ]
    }
   ],
   "source": [
    "# Grayscale\n",
    "gray = cv2.cvtColor(erosion,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Finding Contours\n",
    "# Use a copy of your image e.g. edged.copy(), since findContours alters the image\n",
    "_, contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "# Draw all contours\n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(image_BGR, contours, -1, (0,255,0), 3)\n",
    "\n",
    "cv2.imshow('Contours', image_BGR)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[574 470]]\n",
      "[[598 532]]\n",
      "[[466 468]]\n",
      "[[489 532]]\n",
      "470\n",
      "576\n",
      "484\n",
      "576\n",
      "[[[576 470]]\n",
      "\n",
      " [[576 484]]\n",
      "\n",
      " [[575 485]]\n",
      "\n",
      " [[575 509]]\n",
      "\n",
      " [[574 510]]\n",
      "\n",
      " [[574 512]]\n",
      "\n",
      " [[575 513]]\n",
      "\n",
      " [[575 523]]\n",
      "\n",
      " [[574 524]]\n",
      "\n",
      " [[574 530]]\n",
      "\n",
      " [[575 531]]\n",
      "\n",
      " [[587 531]]\n",
      "\n",
      " [[588 532]]\n",
      "\n",
      " [[595 532]]\n",
      "\n",
      " [[595 522]]\n",
      "\n",
      " [[596 521]]\n",
      "\n",
      " [[596 518]]\n",
      "\n",
      " [[597 517]]\n",
      "\n",
      " [[597 482]]\n",
      "\n",
      " [[598 481]]\n",
      "\n",
      " [[598 477]]\n",
      "\n",
      " [[597 476]]\n",
      "\n",
      " [[597 474]]\n",
      "\n",
      " [[598 473]]\n",
      "\n",
      " [[598 471]]\n",
      "\n",
      " [[586 471]]\n",
      "\n",
      " [[585 470]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'append',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'extend',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'pop',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'sort']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(contours[0][0])\n",
    "print(np.amin(contours[0],0))\n",
    "print(np.amax(contours[0],0))\n",
    "print(np.amin(contours[1],0))\n",
    "print(np.amax(contours[1],0))\n",
    "# print(contours[0][-1])\n",
    "# print(contours[0])\n",
    "# let's verify\n",
    "contourOne = contours[0]\n",
    "print(np.amin(contourOne[0]))\n",
    "print(np.amax(contourOne[0]))\n",
    "print(np.amin(contourOne[1]))\n",
    "print(np.amax(contourOne[1]))\n",
    "\n",
    "print(contourOne)\n",
    "dir(contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with numpy arrays\n",
    "The contours data is in an array, but not a standard python array -- it is an ndarray from the numpy package.  Arrays are kind of what numpy is about, so it's worth exploring them a bit.  We want to use the contours data for two purposes:\n",
    "1.  determine position relative to the camera's orientation\n",
    "2.  determine (relative) distance\n",
    "\n",
    "In theory, if we can do that, we know the direction and distance the robot must travel to reach the target.\n",
    "\n",
    "Let's see what we can get from the numpy array, starting with how many dimensions it has -- using ndarray.ndim\n",
    "\n",
    "We have this code in our script:\n",
    "```python\n",
    "_, contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "```\n",
    "This code finds \"contours\" (think shapes defined by continuous edges) in the image.  There are three things returned, an actual image, which we don't need, so we assign it to \"_\" (this tells python to throw it away).  The second is \"contours\" -- which is a list of numpy arrays (yeah, lots going on here...)\n",
    "\n",
    "What this means is that to use the numpy array functions (like ndim), we will need to pull items from the list...\n",
    "\n",
    "(for convenience, I'm going to pull the code from above into a single cell, so you don't have to run every cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 2\n",
      "3\n",
      "(27, 1, 2)\n",
      "3\n",
      "(18, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_image_file(image_file):        # I used a function here to combine the test with the load\n",
    "    if(os.path.isfile(image_file)):     # os.path.isfile returns true if the file exists, why is this needed?\n",
    "\t    img = cv2.imread(image_file)\n",
    "    else:\n",
    "\t    print(\"Invalid file, exiting....\")\n",
    "\t    exit(1)\n",
    "    return(img)\n",
    "\n",
    "# this sample has \"lit up\" reflective tape\n",
    "#\n",
    "image_file = \"../../images/tape_sample_images/sample7.png\"\n",
    "\n",
    "image_BGR = load_image_file(image_file)\n",
    "\n",
    "# convert from BGR to HSV\n",
    "image_HSV = cv2.cvtColor(image_BGR, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# define range of green color in HSV\n",
    "lower_tape = np.array([50,90,110])\n",
    "upper_tape = np.array([100,255,255])\n",
    "\n",
    "# Threshold the HSV image to get only the tape\n",
    "mask = cv2.inRange(image_HSV, lower_tape, upper_tape)\n",
    "\n",
    "# Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(image_BGR,image_BGR, mask= mask)\n",
    "\n",
    "cv2.imshow('res',res)\n",
    "\n",
    "# Erosion -- will get rid of some of the \"noise\".  We are looking for big objects -- small pixel stuff\n",
    "#            is probably just \"noise\".  Erosion will remove smaller details\n",
    "#\n",
    "# Let's define our kernel size - impacts the extent of the removal\n",
    "#\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "# Now we erode\n",
    "erosion = cv2.erode(res, kernel, iterations = 1)\n",
    "cv2.imshow('Erosion', erosion)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(erosion,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Finding Contours\n",
    "# Use a copy of your image e.g. edged.copy(), since findContours alters the image\n",
    "_, contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "# Draw all contours\n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(image_BGR, contours, -1, (0,255,0), 3)\n",
    "\n",
    "cv2.imshow('Contours', image_BGR)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "###\n",
    "# NEW CODE STARTS HERE\n",
    "###\n",
    "\n",
    "for contour in contours:\n",
    "    print(contour.ndim)\n",
    "    print(contour.shape)\n",
    "    print(contour[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour #0\n",
      "3\n",
      "(27, 1, 2)\n",
      "minPoint [574 470], maxPoint [598 532]\n",
      "width 24, height 62\n",
      "Contour #1\n",
      "3\n",
      "(18, 1, 2)\n",
      "minPoint [466 468], maxPoint [489 532]\n",
      "width 23, height 64\n",
      "Shape(min_pt=array([574, 470], dtype=int32), max_pt=array([598, 532], dtype=int32), width=24, height=62)\n",
      "Shape(min_pt=array([466, 468], dtype=int32), max_pt=array([489, 532], dtype=int32), width=23, height=64)\n",
      "[[574 470]\n",
      " [466 468]\n",
      " [598 532]\n",
      " [489 532]]\n",
      "Complete Shape:  min [466 468], max [598 532]\n"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "foundShapes = []\n",
    "\n",
    "class Shape(NamedTuple):\n",
    "    min_pt: tuple\n",
    "    max_pt: tuple\n",
    "    width: int\n",
    "    height: int\n",
    "\n",
    "for i, contour in enumerate(contours):\n",
    "    print(f\"Contour #{i}\")\n",
    "    print(contour.ndim)\n",
    "    print(contour.shape)\n",
    "    \n",
    "    minPoint = np.amin(contour,0)[0]\n",
    "    maxPoint = np.amax(contour,0)[0]\n",
    "    \n",
    "    print(f\"minPoint {minPoint}, maxPoint {maxPoint}\")\n",
    "    \n",
    "    width = maxPoint[0]-minPoint[0]\n",
    "    height = maxPoint[1]-minPoint[1]\n",
    "    \n",
    "    shape = Shape(minPoint,maxPoint,width,height)\n",
    "    foundShapes.append(shape)\n",
    "    print(f\"width {width}, height {height}\")\n",
    "    \n",
    "for shape in foundShapes:\n",
    "    print(shape)\n",
    "\n",
    "completeShape=np.vstack((foundShapes[0].min_pt,foundShapes[1].min_pt,foundShapes[0].max_pt,foundShapes[1].max_pt))\n",
    "print(completeShape)\n",
    "\n",
    "min_pt=np.amin(completeShape,0)\n",
    "max_pt=np.amax(completeShape,0)\n",
    "\n",
    "print(f\"Complete Shape:  min {min_pt}, max {max_pt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center Point is [532 500]\n"
     ]
    }
   ],
   "source": [
    "# Let's find the center of two points in our shape\n",
    "\n",
    "def findCenterPt(min_pt, max_pt):\n",
    "    x_coord = int(((max_pt[0]-min_pt[0])/2)+min_pt[0])\n",
    "    y_coord = int(((max_pt[1]-min_pt[1])/2)+min_pt[1])\n",
    "    \n",
    "    centerPt = np.array([x_coord,y_coord])\n",
    "    return(centerPt)\n",
    "\n",
    "\n",
    "centerPt = findCenterPt(min_pt,max_pt)\n",
    "\n",
    "print(f\"Center Point is {centerPt}\")\n",
    "\n",
    "centerTgtImage = cv2.circle(image_BGR, tuple(centerPt), 10, (0,0,255),-1)\n",
    "\n",
    "cv2.imshow(\"Target Acquired\", centerTgtImage)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
